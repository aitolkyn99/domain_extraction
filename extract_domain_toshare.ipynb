{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f88358-fa7c-4676-9c64-77334a6b4b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "#Create a spark context\n",
    "import wmfdata\n",
    "spark = wmfdata.spark.get_session(type='yarn-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b01213-3d18-496c-835b-283d0226c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc38ba0-c618-4d26-9e87-a8b8509c953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.ArrayType(T.StringType()))\n",
    "def extract_urls(wikitext):\n",
    "    links_regexp = re.compile('https?://[^\\s]+')\n",
    "    refs = links_regexp.findall(wikitext)\n",
    "    return refs\n",
    "    \n",
    "@F.udf(returnType=T.StringType())\n",
    "def get_domain(url): \n",
    "    def remove_prefix(text, prefix):\n",
    "        if text.startswith(prefix):\n",
    "            return text[len(prefix):]\n",
    "        return text \n",
    "    \n",
    "    try: \n",
    "        domain = remove_prefix(urlparse(url).netloc,'www.')\n",
    "        if domain == 'web.archive.org':\n",
    "            target_url = 'http'+url.split('http')[2]\n",
    "            return remove_prefix(urlparse(target_url).netloc,'www.')\n",
    "        return domain\n",
    "    except: return None   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0665ebd1-e07b-44ae-b7c2-1ae15888eea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.4 ms, total: 3.4 ms\n",
      "Wall time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "snapshot =\"2022-10\"\n",
    "\n",
    "wikihistory_revs = spark.sql('''\n",
    "    SELECT \n",
    "        wiki_db, page_id, revision_id, revision_text\n",
    "    FROM \n",
    "        wmf.mediawiki_wikitext_history\n",
    "    WHERE \n",
    "        page_namespace=0\n",
    "        AND snapshot=\"{snapshot}\" \n",
    "'''.format(snapshot=snapshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d4f8913-5ce7-4365-a884-e2d8de753984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[wiki_db: string, page_id: bigint, url: string, revision_id: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikihistory_revs = wikihistory_revs.withColumn('urls', extract_urls(F.col('revision_text'))) \n",
    "wikihistory_revs = wikihistory_revs.withColumn(\"url\", F.explode(F.col('urls'))).drop(\"urls\",\"revision_text\")\n",
    "wikihistory_revs = wikihistory_revs.groupBy('wiki_db','page_id','url').agg({\"revision_id\": \"min\"})\\\n",
    "                    .withColumnRenamed('min(revision_id)','revision_id')\n",
    "wikihistory_revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd0d2ec2-bdec-4c56-b85d-16ccaa03ef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[wiki_db: string, page_id: bigint, url: string, revision_id: bigint, domain: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_domains = wikihistory_revs.withColumn(\"domain\", get_domain(F.col('url')))\n",
    "wiki_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c24097d-3bea-4a8c-86ba-c449aceb0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2368d1b-ca99-4bde-8602-1212149a97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_domains.write.parquet('urls/all_links_domain.parquet',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0b8cc-df92-4360-8163-b6a039c7a36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdf4ed-7062-488e-b2c8-f7ba143e671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a domain list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211a385-eb25-4cc2-8bbe-bb48f1127c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.where(F.col('domain')!='').select('domain').distinct().write.csv('urls/url_list.csv', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ebb2f-1a6a-4392-b087-bb3457a05b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -text urls/url_list.csv/* |gzip >> data/url_list.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5256a2-6571-4c62-b48e-fbbaaa5b7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdf = pd.read_csv('data/url_list.csv.gz', warn_bad_lines=True, error_bad_lines=False, names=['domain'])\n",
    "\n",
    "#https://stackoverflow.com/questions/26093545/how-to-validate-domain-name-using-regex\n",
    "pdf[pdf.domain.str.match(\"^[a-zA-Z0-9][a-zA-Z0-9-]{1,61}[a-zA-Z0-9](?:\\.[a-zA-Z]{2,})+$\")].sort_values('domain_length').reset_index(drop=True).to_csv('data/domain_list_filtered.csv.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
